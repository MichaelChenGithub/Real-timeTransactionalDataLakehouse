from pyspark.sql import SparkSession

def main():
    print("ğŸš€ Starting REAL Pure S3A Debug Test (Hijacking spark_catalog)...")
    
    spark = SparkSession.builder \
        .appName("PureS3Debug") \
        .config("spark.sql.catalog.spark_catalog", "org.apache.iceberg.spark.SparkCatalog") \
        .config("spark.sql.catalog.spark_catalog.type", "hadoop") \
        .config("spark.sql.catalog.spark_catalog.warehouse", "s3a://warehouse/") \
        .config("spark.hadoop.fs.s3a.endpoint", "http://minio:9000") \
        .config("spark.hadoop.fs.s3a.access.key", "admin") \
        .config("spark.hadoop.fs.s3a.secret.key", "password") \
        .config("spark.hadoop.fs.s3a.path.style.access", "true") \
        .config("spark.hadoop.fs.s3a.connection.ssl.enabled", "false") \
        .config("spark.hadoop.fs.s3a.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem") \
        .config("spark.hadoop.fs.s3a.endpoint.region", "us-east-1") \
        .getOrCreate()

    # æ¸¬è©¦å¯«å…¥ S3 (æ³¨æ„ï¼šæˆ‘å€‘ç¾åœ¨ç”¨ spark_catalog äº†ï¼Œæ‰€ä»¥ä¸éœ€è¦æŒ‡å®š catalog nameï¼Œæˆ–æ˜¯ç›´æ¥å¯«è·¯å¾‘)
    try:
        print("1ï¸âƒ£  Attempting to write to 's3a://warehouse/test_hijack'...")
        data = [("Alice", 1), ("Bob", 2)]
        df = spark.createDataFrame(data, ["name", "age"])
        
        # ç›´æ¥å¯«å…¥ MinIO è·¯å¾‘
        df.write.mode("overwrite").parquet("s3a://warehouse/test_hijack")
        print("âœ… Write Successful!")
    except Exception as e:
        print("âŒ Write Failed!")
        print(e)
        return

    # æ¸¬è©¦è®€å–
    try:
        print("2ï¸âƒ£  Attempting to read back...")
        spark.read.parquet("s3a://warehouse/test_hijack").show()
        print("âœ… Read Successful!")
    except Exception as e:
        print("âŒ Read Failed!")
        print(e)

if __name__ == "__main__":
    main()